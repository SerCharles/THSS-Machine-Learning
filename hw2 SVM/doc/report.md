---
typora-root-url: ./
---

## 1.基本情况

我使用numpy实现了线性SVM和带高斯核的SVM。

具体实现细节和课件类似。线性核中，我将b并入W作为其最后一维，将x的最后一维加上1，以消除b使得代码更清晰。高斯核的bandwidth我使用向量间欧氏距离的中位数。

数据方面，因为数据各维之间差异较大，容易导致过拟合，我进行了**归一化处理**。

我的优化方法是minibatch SGD，同时，我比较了使用全部参数W的平均值，以及只使用W本身进行测试的两种方式。

经过超参数调优，线性SVM运行结果如下：

训练loss图示如下：

![loss_linear](/loss_linear.png)

测试准确率最高72.92%，验证准确率80.63%



带高斯核的SVM运行结果如下：

训练loss图示如下：

![loss_kernel](/loss_kernel.png)

测试准确率最高81.25%，验证准确率79.37%

## 2.超参数选择

我使用grid search进一步进行超参数选择，得到的超参数和结果如下：

|          | 参数是否取平均 | 正则化方法 | 正则化参数reg | 学习率 | batch size | 准确率 |
| -------- | -------------- | ---------- | ------------- | ------ | ---------- | ------ |
| 线性模型 | 是             | L1         | 1             | 1e-8   | 128        | 81.87% |
| 高斯核   | 否             | L2         | 0.01          | 0.01   | 16         | 80.63% |

## 3.和sklearn比较

| 测试准确率 | 我的   | sklearn |
| ---------- | ------ | ------- |
| 线性模型   | 81.87% | 80.00%  |
| 高斯核     | 80.63% | 82.50%  |

比较得到，两者准确率相差不多，可以说明我模型实现的正确性

